function [adaboostModel,y_pred_adaboost,adaboost_rmse, accuracy] = AdaBoost(cv, X, y,k_fold, adaboost_rmse)
%XGBOOST Summary of this function goes here
% Loop over each fold
% for i = 1:k_fold
    % Split the data into training and testing sets
    % Reshuffle X and y using a random permutation of indices
    numSamples = size(X, 1);
    randIndices = randperm(numSamples);  % Generate a random permutation of indices
    X = X(randIndices, :);               % Shuffle X
    y = y(randIndices); 
    X_train = X(training(cv), :);
    X_test = X(test(cv), :);
    y_train = y(training(cv), :);
    y_test = y(test(cv), :);

    % Train AdaBoost model (since now it's binary classification)
    adaboostModel = fitcensemble(X_train, y_train, 'Method', 'AdaBoostM1');

    % % Predict on test data
    y_pred_adaboost = predict(adaboostModel, X_test);
    % 
    % % Evaluate performance (Mean Squared Error for regression)
    mse = mean((y_test - y_pred_adaboost).^2);
    disp(['Mean Squared Error: ', num2str(mse)]);
    
    adaboost_rmse = sqrt(mean((y_pred_adaboost - y_test).^2));
    % Train AdaBoost
%     adaboostModel = fitensemble(X_train, y_train, 'AdaBoostM1', 100, 'Tree', 'Type', 'regression');
%     y_pred_adaboost = predict(adaboostModel, X_test);
%     adaboost_rmse(i) = sqrt(mean((y_pred_adaboost - y_test).^2));
    confMat = confusionmat(y_test, y_pred_adaboost);
    accuracy = sum(diag(confMat)) / sum(confMat(:)) * 100;
    disp(['Adaboost Accuracy: ', num2str(accuracy), '%']);
    Write2File("Accuracy", "AdaBoostResults.txt", [num2str(accuracy), '%']);
    Write2File("Mean Squared Error:", "AdaBoostResults.txt", [num2str(mse)]);
    
% end

end

